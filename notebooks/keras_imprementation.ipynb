{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/morita/.conda/envs/morita/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morita/.conda/envs/morita/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "WARNING:tensorflow:From /home/morita/.conda/envs/morita/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morita/.conda/envs/morita/lib/python3.7/site-packages/ipykernel_launcher.py:33: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49500 samples, validate on 10500 samples\n",
      "Epoch 1/50\n",
      "49500/49500 [==============================] - 3s 70us/step - loss: 0.3683 - val_loss: 0.2748\n",
      "Epoch 2/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.2677 - val_loss: 0.2614\n",
      "Epoch 3/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.2516 - val_loss: 0.2420\n",
      "Epoch 4/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.2326 - val_loss: 0.2240\n",
      "Epoch 5/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.2172 - val_loss: 0.2107\n",
      "Epoch 6/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.2059 - val_loss: 0.2010\n",
      "Epoch 7/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1976 - val_loss: 0.1937\n",
      "Epoch 8/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1909 - val_loss: 0.1876\n",
      "Epoch 9/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1852 - val_loss: 0.1821\n",
      "Epoch 10/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1800 - val_loss: 0.1771\n",
      "Epoch 11/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1752 - val_loss: 0.1725\n",
      "Epoch 12/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1709 - val_loss: 0.1683\n",
      "Epoch 13/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1669 - val_loss: 0.1645\n",
      "Epoch 14/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1632 - val_loss: 0.1609\n",
      "Epoch 15/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1598 - val_loss: 0.1576\n",
      "Epoch 16/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1565 - val_loss: 0.1544\n",
      "Epoch 17/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1534 - val_loss: 0.1514\n",
      "Epoch 18/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1505 - val_loss: 0.1486\n",
      "Epoch 19/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1478 - val_loss: 0.1460\n",
      "Epoch 20/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1452 - val_loss: 0.1435\n",
      "Epoch 21/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1429 - val_loss: 0.1412\n",
      "Epoch 22/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1406 - val_loss: 0.1391\n",
      "Epoch 23/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1385 - val_loss: 0.1370\n",
      "Epoch 24/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1365 - val_loss: 0.1350\n",
      "Epoch 25/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1345 - val_loss: 0.1332\n",
      "Epoch 26/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1326 - val_loss: 0.1313\n",
      "Epoch 27/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1308 - val_loss: 0.1296\n",
      "Epoch 28/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1291 - val_loss: 0.1279\n",
      "Epoch 29/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1274 - val_loss: 0.1262\n",
      "Epoch 30/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1258 - val_loss: 0.1247\n",
      "Epoch 31/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1243 - val_loss: 0.1232\n",
      "Epoch 32/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1228 - val_loss: 0.1217\n",
      "Epoch 33/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1214 - val_loss: 0.1204\n",
      "Epoch 34/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1200 - val_loss: 0.1191\n",
      "Epoch 35/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1187 - val_loss: 0.1178\n",
      "Epoch 36/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1175 - val_loss: 0.1167\n",
      "Epoch 37/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1164 - val_loss: 0.1156\n",
      "Epoch 38/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1153 - val_loss: 0.1145\n",
      "Epoch 39/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1143 - val_loss: 0.1136\n",
      "Epoch 40/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1133 - val_loss: 0.1126\n",
      "Epoch 41/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1124 - val_loss: 0.1118\n",
      "Epoch 42/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1116 - val_loss: 0.1110\n",
      "Epoch 43/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1108 - val_loss: 0.1102\n",
      "Epoch 44/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1101 - val_loss: 0.1095\n",
      "Epoch 45/50\n",
      "49500/49500 [==============================] - 1s 23us/step - loss: 0.1094 - val_loss: 0.1089\n",
      "Epoch 46/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1088 - val_loss: 0.1083\n",
      "Epoch 47/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1082 - val_loss: 0.1077\n",
      "Epoch 48/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1076 - val_loss: 0.1071\n",
      "Epoch 49/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1071 - val_loss: 0.1067\n",
      "Epoch 50/50\n",
      "49500/49500 [==============================] - 1s 24us/step - loss: 0.1066 - val_loss: 0.1061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# AutoEncoder ネットワーク構築\n",
    "encoding_dim = 32\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input=input_img, output=decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    " \n",
    "# MNIST データ読み込み\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    " \n",
    "# データの前準備\n",
    "x_train, x_valid = train_test_split(x_train, test_size=0.175)\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_valid = x_valid.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_valid = x_valid.reshape((len(x_valid), np.prod(x_valid.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    " \n",
    "# 学習\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                nb_epoch=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_valid, x_valid))\n",
    " \n",
    "# 出力画像の取得\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    " \n",
    "# サンプル画像表示\n",
    "n = 6\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # テスト画像を表示\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    " \n",
    "    # 出力画像を表示\n",
    "    ax = plt.subplot(2, n, i+1+n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(\"result.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/external/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 4268917.56it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/external/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/external/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 63746.75it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/external/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/external/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 877468.74it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/external/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/external/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 24062.91it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/external/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_data = MNIST('../../data/external/mnist', train=True, download=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
